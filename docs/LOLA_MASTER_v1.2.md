# LoLA ‚Äî Loka Learning Avatar Master Reference (v1.2 ‚Äî 2026-02-22)

**Status:** CANONICAL ‚Äî supersedes LOLA_PRD_v1.md and LOLA_PRD_v2.md  
**Scope:** LoLA (Loka Learning Avatar) ‚Äî the AI coaching layer of the Loka platform  
**Sync:** This document lives in both Claude.ai Project Knowledge and `docs/LOLA_MASTER.md`.

---

## Version History

> **MAINTENANCE RULE:** Every time this document is updated ‚Äî by Claude.ai, Claude Code, or Ryan ‚Äî the updater MUST: (1) bump the version and date in the H1 title above, (2) add a new entry to the top of this log, (3) rename the file to match: `v{X.X} ‚Äî {YYYY-MM-DD} LOLA_MASTER.md`. The filename, title, and changelog must always show the same version and date. Use the format below. Never delete previous entries.

| Version | Timestamp (UTC) | Updated By | Summary of Changes |
|---------|-----------------|------------|-------------------|
| 1.2 | 2026-02-22T14:30:00Z | Claude Code (Opus 4.6) | Updated to reflect actual built state after Phase 1 build sessions. Tech stack updated: Gemini 2.5 Flash Native Audio (not GPT-4o), TalkingHead with AnalyserNode lip sync (not HeadAudio), Kore voice. Added ¬ß5 actual project structure matching `server/` + `src/` layout. Updated ¬ß4 with 4 demo profiles (A/B/C/D), both-direction language support (EN‚ÜíJA added), 3 L1 pattern files. Documented actual API architecture: FastAPI WebSocket proxy, API key mode, session token auth. Added implementation status tracking to ¬ß7. |
| 1.1 | 2026-02-20T15:00:00Z | Claude.ai (Opus 4.6) | Added ¬ß4 Academic Foundations subsection with principle-by-principle source mapping (Dweck, Sweller, Immordino-Yang, Roediger, Flavell, Hammond, Bandler & Grinder, Paling). Created companion doc `LOLA_12_PRINCIPLE_ACADEMIC_FOUNDATIONS.md` with full ISBNs, research findings, and hackathon/investor Q&A guidance. |
| 1.0 | 2026-02-20T14:00:00Z | Claude.ai (Opus 4.6) | Initial master doc. Consolidated from LOLA_PRD_v1.md, LOLA_PRD_v2.md, lola_shizuku_strategic_scope.md, LOKALINGO_MASTER ¬ß9, and competitive research update brief v3. Strategic repositioning: adaptive coaching engine + educator creator platform + self-marketing pipeline. Co-active triangle architecture (Educator ‚Üî AI ‚Üî Learner). Personality framework integration roadmap (MBTI, Enneagram, Big Five, DISC, StrengthsFinder, EQ). 12-principle coaching framework as ¬ß4. Hackathon MVP demo spec. Japan market crisis context. Praktika competitive analysis. CIP as internal architecture shorthand only ‚Äî natural language in all positioning. |

---

## Document Purpose

This is the single source of truth for LoLA (Loka Learning Avatar) ‚Äî the AI coaching layer of the Loka platform. It consolidates specifications from multiple documents into one reference that both Claude Code and Claude.ai can use. When this document conflicts with older docs, this document wins.

### Relationship to Other Master Docs

| Document | Scope | Relationship |
|----------|-------|-------------|
| `PROJECT_MASTER_TEMPLATE.md` | Standard section structure for all project masters | This document follows the template ‚Äî ¬ß8 is always Dev & Deployment, ¬ß3 is always API, etc. |
| `LOKALINGO_MASTER.md` | Loka The Living Textbook ‚Äî core EdTech SaaS platform | Sibling product ‚Äî LoLA integrates with Loka via ¬ß9 boundary and shared learning data loop |
| `ORBWEVA_MASTER.md` | ORBWEVA product stack (ARC, AER, Grow, Labs) | Parent business ‚Äî methodology, positioning, operational standards |
| This document | LoLA ‚Äî AI coaching layer with adaptive methodology, creator platform, and content pipeline | The AI coaching companion to Loka's classroom tools |

### Superseded Documents

| Document | What It Covered | Status |
|----------|----------------|--------|
| `LOLA_PRD_v1.md` | Initial PRD ‚Äî basic architecture, market domains, acquisition funnel | Archived ‚Äî content merged here |
| `LOLA_PRD_v2.md` | Stage 1 workflows, tool stack, Google Sheets schema, reference packs | Archived ‚Äî content merged here |
| `lola_shizuku_strategic_scope.md` | Shizuku AI market validation + Praktika competitive analysis | Archived ‚Äî content merged into ¬ß10 |

### Documents That Remain Separate

| Document | Why It Stays |
|----------|-------------|
| `LOKALINGO_MASTER.md` | Separate platform with its own architecture, codebase, and roadmap |
| `lokalingo_dual_value_positioning_guide.md` | Sales collateral ‚Äî downstream of positioning changes here |

---

## Product Overview

### What LoLA Is

LoLA (Loka Learning Avatar) is the AI coaching layer of the Loka Living Textbook platform. It is an adaptive coaching platform ‚Äî not a chatbot ‚Äî with three interlocking capabilities:

**Adaptive Coaching Engine** ‚Äî A 12-principle neuroscience framework (neuroscience + neurolanguage coaching + NLP) that serves as the foundation for integrating personality frameworks (MBTI, Enneagram, Big Five, DISC, StrengthsFinder, EQ) and learning science models. Every learner gets coaching adapted to their psychological profile, not just their skill level. "No two brains are alike" made technical.

**Educator Creator Platform** ‚Äî Educators, coaches, and subject matter experts build, own, and monetize their own AI coaching avatars across any knowledge domain. Language learning is the first vertical; the architecture supports any discipline where humans learn through co-active conversation.

**Self-Marketing Pipeline** ‚Äî LoLA avatars generate their own social media content and build organic audiences, converting followers into paying learners. Competitors spend VC money on app store acquisition. LoLA avatars attract their own learners.

No competitor has any of these three capabilities. No competitor has two.

### The Co-Active Triangle

Every AI language learning competitor offers a single line: AI ‚Üî Learner. The educator doesn't exist in their model.

Loka + LoLA creates a triangle:

```
         EDUCATOR
        ‚Üó        ‚Üñ
  Learning data   Live teaching
  & insights      & human connection
      ‚Üó                ‚Üñ
  AI (LoLA) ‚Üê‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Äî‚Üí LEARNER
        Adaptive coaching
     powered by shared data
```

- **Educator ‚Üî Learner** ‚Äî classroom, live teaching, human connection
- **AI ‚Üî Learner** ‚Äî LoLA adaptive coaching, personality-informed practice, always available
- **AI ‚Üî Educator** ‚Äî learning data, progress insights, generated curriculum suggestions

Shared learning data flows through all three sides. The educator's classroom captures feed the AI. The AI's coaching sessions feed the educator's dashboard. The learner benefits from both and generates data for both. **Co-active** means all three participants actively contribute to the learning.

A learner without an educator still gets the AI ‚Üî Learner side ‚Äî it works standalone. An educator without LoLA still gets Loka classroom tools ‚Äî they work standalone. But together, the co-active triangle is where the Living Textbook philosophy reaches full power. That's the natural upsell/cross-sell.

### The Capture ‚Üí Generate ‚Üí Deliver Loop (Internal Architecture)

> **Naming note:** "CIP" is internal shorthand for this loop. In all positioning, pitch, and learner-facing language, describe the loop naturally or use "Where Conversations Become Curriculum." Never expose the acronym externally.

**Capture** ‚Äî Every interaction (Loka exercise, LoLA conversation, classroom session) produces learning data: what the learner was trying to express, what went wrong, what patterns repeat, when they hesitate, what they self-correct, how they respond emotionally to errors. With personality profiling, capture also includes the learner's psychological response patterns.

**Generate** ‚Äî AI transforms captured data into personalized material adapted to the learner's psychological profile. An analytical learner gets pattern explanations. A social learner gets conversation scenarios. Same error, different coaching approach.

**Deliver** ‚Äî Generated material reaches the learner at the right time, difficulty, and modality ‚Äî through whichever mode they're in (Loka exercise, LoLA conversation, or educator suggestion for next class).

The loop repeats: delivery creates new interactions ‚Üí new captures ‚Üí new generation ‚Üí new delivery. The textbook rewrites itself with every session.

**Example ‚Äî The Co-Active Loop in Practice:**

*Monday ‚Äî Yuki does a Loka grammar exercise. The system captures that she consistently drops articles. Her profile says she's analytical and structure-first.*

*Tuesday ‚Äî Yuki has a LoLA conversation. The avatar already knows about the article pattern. It proactively scaffolds scenarios where articles matter and coaches through her analytical profile.*

*Wednesday ‚Äî Yuki's teacher opens her Loka dashboard. Sees data from both the exercise and LoLA session. Knows Yuki is improving in structured contexts but still drops articles in free conversation. Focuses classroom time on exactly that gap.*

*Thursday ‚Äî LoLA references Yuki's progress: "Remember our restaurant conversation? You nailed the articles there. Let's try a new context." Anchoring using data from across the triangle.*

### Key Distinction: Loka vs. LoLA

| | Loka The Living Textbook | LoLA |
|---|---|---|
| **Focus** | Teacher-led education management | AI-led adaptive coaching through conversation |
| **Users** | Teachers (primary), students (secondary) | Learners (primary), educators/creators (secondary) |
| **Revenue** | Per-seat subscription ($6/seat) | Usage-based (pay for engagement) + marketplace fee (20%) |
| **Domain** | Language learning (LokaLingo) | Any domain where humans learn through co-active conversation |
| **AI Role** | Augments teacher workflow (canvas, assessment) | IS the coach ‚Äî adaptive, personality-informed, methodology-driven |
| **Tech Stack** | Laravel + PostgreSQL + AWS | n8n + Vercel + Next.js + Supabase (MVP) |
| **Status** | Production (running Accent Language School) | Pre-MVP ‚Äî hackathon build imminent |

---

## ¬ß0 ‚Äî Mission, Philosophy & Brand Framework

### Founding Statement

> "No two brains are alike."

This is the operating principle behind everything LoLA builds. Every competitor treats learners as a difficulty level ‚Äî beginner, intermediate, advanced. LoLA treats learners as psychological profiles. The same error gets coached completely differently depending on who's making it and why.

### The Living Textbook Philosophy

"Where Conversations Become Curriculum" ‚Äî every conversation a learner has, whether with an AI avatar, in a Loka exercise, or in a classroom, becomes the raw material for the next piece of personalized curriculum. The textbook isn't written by a publisher. It's written by the learner's own journey.

### Three Pillars

| Pillar | What It Means | How LoLA Applies It |
|--------|--------------|-------------------|
| **Nurture** | A co-active learning environment where mistakes are celebrated, not feared | 12-principle framework: emotional regulation, growth mindset, reframing errors as progress |
| **Guide** | CEFR-aligned adaptive assessment giving clear paths forward | Personality profiling + learning data ‚Üí coaching adapted to individual progression |
| **Accelerate** | AI-powered tools that make practice efficient, targeted, engaging | Adaptive coaching, spaced repetition from captured data, personality-optimized delivery |

### Brand Language Rules

| Use | Don't Use |
|-----|-----------|
| "Adaptive coaching" | "AI-powered avatars" (as differentiator) |
| "Coaching that adapts to who you are" | "Available 24/7, no judgment" |
| "Personality-adaptive ‚Äî same error, different approach" | "Personalized learning experiences" |
| "Co-active conversations with AI and human educators" | "Scalable, personalized learning" |
| "Where Conversations Become Curriculum" | "CIP" (externally) |
| Describe capabilities directly | "Stage 1/2/3" labels (externally) |

---

## ¬ß1 ‚Äî Product Architecture

### Three-Stage Build Sequence

> **Internal roadmap labels only.** Do not use "Stage 1/2/3" in positioning or pitch. Describe what each capability does.

**Content Pipeline (formerly Stage 1):** One-click character creation ‚Üí image generation ‚Üí voice selection ‚Üí script generation ‚Üí video production ‚Üí multi-platform publishing. Avatars generate their own social media content and build organic audiences.

**SaaS Platform (formerly Stage 2):** User registration, subscription, self-service character creation, voice/text chat with coaching avatars, private transcripts, learning data tracking.

**Marketplace (formerly Stage 3):** Educators create and monetize AI coaching avatars. Learners subscribe to multiple coaches. Spaced repetition and quiz systems. Learning analytics and progress tracking. Revenue sharing.

### Content Pipeline Architecture (Current Build)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                    CONTENT PIPELINE                          ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  Character Creation (S1-W01 ‚Äî ‚úÖ BUILT)                    ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Form UI ‚Üí Prepare Data ‚Üí Save Initial Record       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                              ‚Üì                      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                  ‚Üì                  ‚Üì     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    üñºÔ∏è Image Gen      üé§ Voice Select    üìù Script  ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    (Kie.ai)          (ElevenLabs)       (Claude)   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ    30-60 sec         2-3 sec            5-10 sec   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚Üì                  ‚Üì                  ‚Üì     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ         ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                            ‚Üì                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                    Merge ‚Üí Sheet ‚Üí Success          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                            ‚Üì                        ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ              (Async) Reference Pack Generator       ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Reference Pack (S1-W01b ‚Äî ‚úÖ BUILT)                       ‚îÇ
‚îÇ  9 image variations for visual consistency                  ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Video Generator (S1-W02 ‚Äî üî≤ TO BUILD)                   ‚îÇ
‚îÇ  Character + Script ‚Üí TTS ‚Üí Video ‚Üí Captions ‚Üí Queue       ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Content Publisher (S1-W03 ‚Äî üî≤ TO BUILD)                  ‚îÇ
‚îÇ  Queue ‚Üí Format ‚Üí Post (IG, TikTok, YT Shorts, FB)        ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

### Adaptive Coaching Platform Architecture (Hackathon MVP ‚Äî ACTUAL)

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ                 ADAPTIVE COACHING MVP (BUILT)                ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ                                                             ‚îÇ
‚îÇ  Demo Profile Picker (4 profiles)                          ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  Profile A: JA‚ÜíEN Analyst  ‚îÇ  Profile B: JA‚ÜíEN Explorer‚îÇ
‚îÇ  ‚îÇ  Profile C: EN‚ÜíJA Analyst  ‚îÇ  Profile D: EN‚ÜíJA Explorer‚îÇ
‚îÇ  ‚îÇ          ‚Üì                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  GET /api/demo-profiles ‚Üí selects profile           ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  POST /api/profile ‚Üí generates system instruction   ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                            ‚Üì                                ‚îÇ
‚îÇ  Profile-Adaptive Voice Session                            ‚îÇ
‚îÇ  ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê   ‚îÇ
‚îÇ  ‚îÇ  System prompt = 12-principle framework (weighted)   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                + personality profile injection       ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                + L1 patterns (JA/KO/EN)             ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ                + both-direction language support     ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ          ‚Üì                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Browser mic ‚Üí PCM ‚Üí WebSocket ‚Üí FastAPI ‚Üí          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Gemini Live API (native audio, speech-to-speech)   ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ          ‚Üì                                          ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  Gemini audio response ‚Üí WebSocket ‚Üí Browser ‚Üí      ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  AudioWorklet playback ‚Üí AnalyserNode ‚Üí TalkingHead ‚îÇ   ‚îÇ
‚îÇ  ‚îÇ  3D avatar with real-time lip sync + idle anims     ‚îÇ   ‚îÇ
‚îÇ  ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò   ‚îÇ
‚îÇ                                                             ‚îÇ
‚îÇ  Educator Creator View (Dashboard) ‚Äî NOT YET BUILT         ‚îÇ
‚îÇ                                                             ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

---

## ¬ß2 ‚Äî Pricing

### Revenue Model

| Stream | Model | Target |
|--------|-------|--------|
| **Learner direct (B2C)** | Usage-based ‚Äî pay per engagement minutes or subscription | Individual learners entering through LoLA |
| **Educator tools (B2B)** | Subscription ‚Äî per-seat via Loka platform | Educators using Loka classroom tools |
| **Creator marketplace** | Revenue share ‚Äî 80% educator / 20% platform | Educators monetizing LoLA coaching avatars |

### LoLA Acquisition Funnel

The avatar is both the marketing and the product. The same coaching techniques that make social media content engaging make the free trial conversations sticky enough to convert.

**Social Media Hook** ‚Üí Avatars published across YouTube, TikTok, Instagram, LINE as content creators. The viewer connects with a character before signing up.

**Free Trial** ‚Üí Viewer chats with the same avatar they already feel rapport with. Free allocation (20-40 minutes per avatar, 120-180 minutes account-level cap) is enough for the coaching methodology to demonstrate value.

**Transparent Paywall** ‚Üí Learner informed upfront of free allocation. No surprise, no dark pattern. Transition from free to paid feels like natural progression.

**Multi-Avatar Sampling** ‚Üí Single account gets free allocations with multiple avatars. Learner finds their match before committing.

### Anti-Abuse

Layered identity verification: email + phone + device fingerprinting + IP clustering + behavioral fingerprinting + payment method linking + learning profile matching. Learning profiles (error patterns, hesitation patterns, self-correction habits) are nearly impossible to spoof ‚Äî the learner would have to intentionally make different mistakes, defeating the purpose.

---

## ¬ß3 ‚Äî API Architecture

### External APIs (Current)

| Service | Purpose | Auth | Cost |
|---------|---------|------|------|
| **Kie.ai** | Character image generation (nano-banana-pro) | Bearer token | ~$0.05/image |
| **ElevenLabs** | Voice selection + TTS | `xi-api-key` header | $5-22/mo |
| **OpenAI** | GPT-4o for coaching chat + Whisper for STT | API key | Pay-per-use |
| **Anthropic** | Claude for script generation | API key | Pay-per-use |
| **Blotato** | Multi-platform social media publishing | OAuth | ~$19/mo |

### Kie.ai API Endpoints

| Endpoint | Method | Purpose |
|----------|--------|---------|
| `api.kie.ai/api/v1/jobs/createTask` | POST | Submit image generation job |
| `api.kie.ai/api/v1/jobs/recordInfo` | GET | Poll job status until complete |

### ElevenLabs Voice Matching

Priority scoring algorithm:
1. Gender match: +10 points
2. Age match: +5 points
3. Accent match: +5 points
4. Use case (educational): +3 points
5. Premade (not cloned): +2 points

### Future API Needs (MVP)

| Service | Purpose | Notes |
|---------|---------|-------|
| Supabase | Learner profiles, session data, coaching history | PostgreSQL + real-time subscriptions |
| Vercel | Next.js hosting for chat interface | Edge functions for API routes |

---

## ¬ß4 ‚Äî AI & Automation Standards

### The 12-Principle Coaching Framework

This is the foundation layer of LoLA's adaptive coaching architecture. These 12 principles are prepended to ALL AI interactions. The `{TASK_CONTEXT}` section adapts for specific use cases, but the principles are never removed or weakened.

**Neuroscience Principles (WHY the brain learns):**

1. **GROWTH MINDSET** ‚Äî Frame every correction as progress, not deficit. Use "yet" language ("You haven't mastered this yet" not "You got this wrong"). Praise effort and strategy, not innate ability. Mistakes are the raw material of learning.

2. **COGNITIVE LOAD MANAGEMENT** ‚Äî Present information in small, digestible chunks. Connect new concepts to what the learner already knows. Do not overwhelm ‚Äî if extracting many items, prioritize by impact and group related concepts. Quality over quantity.

3. **EMOTIONAL REGULATION** ‚Äî Acknowledge difficulty without judgment. Normalize struggle as part of the learning process. Celebrate incremental progress. Never use language that could shame, discourage, or create anxiety about mistakes.

4. **RETRIEVAL PRACTICE** ‚Äî Design outputs that require active recall, not passive recognition. Questions should prompt the learner to retrieve from memory. Use the teach-back principle where possible.

5. **METACOGNITION** ‚Äî Where appropriate, prompt reflection ‚Äî "What strategy helped here?" or "Notice how this connects to..." Help learners see patterns in their own learning.

6. **CULTURAL SENSITIVITY** ‚Äî Respect the learner's cultural and linguistic background. A Japanese learner's path looks different from a Brazilian learner's ‚Äî and that is by design. Frame corrections in context of the learner's world, not against a single cultural norm.

**NLP Communication Patterns (WHAT language patterns to use):**

7. **REFRAMING** ‚Äî Transform negative self-perception into growth narrative. "I made a mistake" ‚Üí "You found a growth edge." "I can't do this" ‚Üí "You haven't unlocked this yet."

8. **PRESUPPOSITIONS** ‚Äî Embed assumed success in all language. "When you use this in your next conversation..." not "If you remember this..." The learner's subconscious absorbs the assumption of competence.

9. **ANCHORING** ‚Äî Associate positive emotional states with learning milestones. Reference previous wins when introducing new challenges: "You mastered [previous concept] ‚Äî this builds on exactly that foundation."

10. **PACING AND LEADING** ‚Äî Match the learner's emotional state before guiding them forward. If frustrated ‚Üí acknowledge ‚Üí validate ‚Üí redirect. Never jump to instruction without establishing rapport.

11. **VAK ADAPTATION** ‚Äî Rotate across Visual, Auditory, and Kinesthetic modalities. Some learners see patterns (visual), some hear rhythm (auditory), some need to do/feel (kinesthetic). Adapt output format to the learner's preference.

12. **META-MODEL QUESTIONING** ‚Äî Challenge limiting beliefs by surfacing the specific structure of the belief. "I always forget this" ‚Üí "Can you remember a time you didn't forget?" Break generalizations that create learned helplessness.

### Personality Framework Integration Architecture

The 12 principles above are the **foundation layer**. They are designed to integrate established personality and learning science frameworks progressively:

| Framework | What It Tells LoLA | How Coaching Adapts |
|-----------|-------------------|-------------------|
| **MBTI** | Cognitive processing style | INTJ gets structured analysis; ESFP gets experiential social scenarios |
| **Enneagram** | Core motivations and fears | Type 3 gets progress metrics; Type 9 gets gentle encouragement without pressure |
| **Big Five (OCEAN)** | Trait spectrum | High neuroticism ‚Üí more emotional regulation; High openness ‚Üí more exploratory exercises |
| **DISC** | Behavioral style | High D gets direct challenge; High S gets patient structured progression |
| **StrengthsFinder** | Natural talents | Coaching leverages existing strengths as bridges rather than focusing on deficits |
| **EQ** | Emotional awareness level | Low EQ ‚Üí explicit emotional scaffolding; High EQ ‚Üí deeper self-reflection |
| **VAK** | Sensory preference | Visual ‚Üí written/diagrammatic; Auditory ‚Üí spoken/rhythm; Kinesthetic ‚Üí action-oriented |

**Integration Roadmap:**

| Phase | What | Technical Approach |
|-------|------|-------------------|
| **MVP (Hackathon)** | 5-question onboarding ‚Üí coaching dimensions | JS mapping function; no framework labels exposed to learner |
| **v1** | Big Five mapping (most empirically validated) | Dynamic system prompt adjusts emotional regulation, pacing, social framing |
| **v2** | MBTI + DISC + Enneagram integration | Multi-framework profile synthesis; richer coaching adaptation |
| **v3** | Optional self-assessment ("I know my MBTI type") | Direct input for faster calibration; educator dashboard showing patterns |

**Design principle:** Learners never need to know about personality frameworks. The system infers and adapts silently. Learners who know their type can optionally input it for faster calibration. The 5-question onboarding is the universal entry point.

### 5-Question Learner Onboarding (MVP)

```
Q1: When you make a mistake in English, what's your first reaction?
   (a) I want to understand WHY I made it ‚Üí Analytical coaching mode
   (b) I feel embarrassed and want to move on ‚Üí Emotional safety mode
   (c) I laugh it off and try again ‚Üí Challenge-forward mode

Q2: How do you prefer to learn new things?
   (a) Show me the rules and patterns ‚Üí Structure-first
   (b) Let me try and figure it out ‚Üí Experience-first
   (c) Show me real examples of people using it ‚Üí Social-contextual

Q3: What motivates you most?
   (a) Seeing measurable progress ‚Üí Metrics-driven
   (b) Feeling more confident ‚Üí Emotion-driven
   (c) Being able to use it in real situations ‚Üí Application-driven

Q4: When practicing English, I prefer:
   (a) Taking my time to think before speaking ‚Üí Reflective pace
   (b) Jumping right in, even if imperfect ‚Üí Action pace

Q5: I learn best when the teacher:
   (a) Explains things thoroughly ‚Üí Depth-first
   (b) Keeps things moving and fun ‚Üí Flow-first
   (c) Connects to things I already know ‚Üí Bridge-building
```

These five answers generate a **Learner Coaching Profile** that maps to relevant dimensions across personality frameworks without requiring learners to know or care about any of them.

### Four Demo Profiles (BUILT)

The current build uses 4 pre-built demo profiles instead of the full onboarding flow. Profiles are selectable from a card picker in the UI:

| Profile | L1 | Direction | Style | Label |
|---------|-----|-----------|-------|-------|
| **A** | Japanese | JA‚ÜíEN | Analytical, structure-first, reflective | "The Analyst" |
| **B** | Japanese | JA‚ÜíEN | Social, action-paced, challenge-forward | "The Explorer" |
| **C** | English | EN‚ÜíJA | Analytical, structure-first, reflective | "JP Beginner (Analyst)" |
| **D** | English | EN‚ÜíJA | Social, experience-first, challenge-forward | "JP Beginner (Explorer)" |

**Both-direction support:** The instruction engine dynamically generates "You are LoLA, a warm and adaptive {target_lang} language coach for {l1_name} speakers" based on the `target_language` field in each L1 pattern file. Adding new L1‚Üítarget combinations is a config change (new pattern file + profile).

### L1 Pattern Files (BUILT)

| File | L1 | Target | Key Patterns |
|------|-----|--------|-------------|
| `server/l1_patterns/japanese.py` | Japanese | English | Articles, tense, pro-drop, plurals, agreement, SOV, L/R |
| `server/l1_patterns/korean.py` | Korean | English | Articles, tense, pro-drop, plurals, agreement, SOV, honorific transfer |
| `server/l1_patterns/english.py` | English | Japanese | Pronoun overuse, SVO‚ÜíSOV, particles, politeness mixing, counters, te-form |

### Academic Foundations ‚Äî Source Reference

> **Full reference doc:** `LOLA_12_PRINCIPLE_ACADEMIC_FOUNDATIONS.md` ‚Äî detailed academic grounding with ISBNs, key findings, competitive implications, and guidance for hackathon/investor Q&A.

The 12 principles were designed by synthesizing three complementary disciplines:

| Discipline | Layer | Core Question | Key Source |
|-----------|-------|--------------|-----------|
| **Neuroscience** | WHY the brain learns | What cognitive structures enable learning? | Dweck, Sweller, Immordino-Yang, Roediger |
| **Neurolanguage Coaching** | HOW to create conditions for learning | How do coaching + brain science accelerate acquisition? | Rachel Paling (ICF-accredited, 2,000+ certified coaches, 70+ countries) |
| **NLP Communication** | WHAT language patterns to use | What patterns shape perception and retention? | Bandler & Grinder, applied coaching techniques |

**Principle-by-principle source mapping:**

| # | Principle | Primary Author | Key Work | Year |
|---|-----------|---------------|----------|------|
| 1 | Growth Mindset | Carol S. Dweck (Stanford) | *Mindset: The New Psychology of Success* | 2006 |
| 2 | Cognitive Load | John Sweller (UNSW) | *Cognitive Load Theory* | 2011 |
| 3 | Emotional Regulation | Mary Helen Immordino-Yang (USC) | *Emotions, Learning, and the Brain* | 2016 |
| 4 | Retrieval Practice | Brown, Roediger & McDaniel (WashU) | *Make It Stick* | 2014 |
| 5 | Metacognition | John H. Flavell (Stanford) | "Metacognition and cognitive monitoring" | 1979 |
| 6 | Cultural Sensitivity | Zaretta Hammond | *Culturally Responsive Teaching and the Brain* | 2015 |
| 7‚Äì12 | NLP Patterns | Bandler & Grinder | *The Structure of Magic* | 1975 |
| ‚Äî | Bridging discipline | Rachel Paling | *Neurolanguage Coaching: Brain Friendly Language Learning* (2nd ed.) | 2017 |

**Competitive significance:** No AI language learning company ‚Äî not Speak, Praktika, ELSA, or Duolingo ‚Äî references any structured coaching methodology, let alone one grounded in ICF-accredited practice with 2,000+ certified practitioners. This is an architectural advantage, not a feature.

### n8n Workflows

| ID | Name | Status | Trigger | Purpose |
|----|------|--------|---------|---------|
| S1-W01 | AI Influencer Creator v3 | ‚úÖ BUILT | n8n Form | Character creation: image + voice + scripts |
| S1-W01b | Reference Pack Generator | ‚úÖ BUILT | Webhook | 9 image variations for visual consistency |
| S1-W02 | Video Generator | üî≤ TO BUILD | Manual/Form | Character + Script ‚Üí Audio ‚Üí Video ‚Üí Captions |
| S1-W03 | Content Publisher | üî≤ TO BUILD | Manual/Scheduled | Queue ‚Üí Format ‚Üí Post across platforms |

---

## ¬ß5 ‚Äî Technical Infrastructure

### Current Stack

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **Automation** | n8n (n8n.orbweva.cloud) | Workflow orchestration for content pipeline |
| **Storage** | Google Sheets | Character database (current) |
| **Image Gen** | Kie.ai (nano-banana-pro) | Character images, 4:5 portrait, 2K PNG |
| **Voice** | ElevenLabs | Voice library matching + TTS |
| **LLM** | Claude / GPT-4o | Script generation, coaching chat |
| **STT** | OpenAI Whisper | Speech-to-text for voice input |
| **Publishing** | Blotato | Multi-platform social media posting |

### MVP Stack (Hackathon Build ‚Äî ACTUAL)

| Layer | Technology | Purpose |
|-------|-----------|---------|
| **LLM** | Gemini 2.5 Flash Native Audio (`gemini-2.5-flash-native-audio-preview-12-2025`) | Speech-to-speech coaching via Live API ‚Äî no separate STT/TTS needed |
| **Backend** | Python 3.10+ / FastAPI / `google-genai` SDK | WebSocket proxy between browser and Gemini Live API |
| **Frontend** | Vanilla JS / Vite / Web Components / Web Audio API | Voice chat interface, profile picker, avatar rendering |
| **3D Avatar** | TalkingHead v1.7 (@met4citizen/talkinghead) + ThreeJS/WebGL | Ready Player Me full-body avatar with lip sync |
| **Lip Sync** | AnalyserNode (Web Audio API) | Real-time playback volume ‚Üí viseme blend shapes (not HeadAudio ‚Äî see notes) |
| **Audio** | AudioWorklets (capture + playback) | PCM streaming, VAD for barge-in |
| **Session State** | In-memory (FastAPI) | Session tokens, rate limiting |
| **Deployment** | Google Cloud Run (target) | Containerized FastAPI + built frontend |

**Key deviation from original spec:** The original plan called for GPT-4o + Whisper + ElevenLabs (text pipeline). The actual build uses Gemini Live API with native audio (speech-to-speech), which eliminates the need for separate STT and TTS services. This is a significant improvement ‚Äî lower latency, native barge-in, and deeper Gemini integration for the hackathon.

**Lip sync approach:** HeadAudio (the planned viseme detection worklet) was not used. Instead, lip sync is driven by an AnalyserNode inserted into the audio output chain (`gainNode ‚Üí analyser ‚Üí destination`). A `requestAnimationFrame` loop reads frequency data from the AnalyserNode and maps volume to viseme blend shapes (`viseme_aa`, `viseme_O`, `viseme_I`, `jawOpen`) via TalkingHead's morph target system. Critical implementation detail: TalkingHead requires both `newvalue` AND `needsUpdate = true` on morph targets ‚Äî without `needsUpdate`, updates are silently skipped (line 1591 of talkinghead.mjs).

---

## ¬ß6 ‚Äî Data & Schema

### Characters Tab (Google Sheets ‚Äî Current)

| Column | Type | Description |
|--------|------|-------------|
| character_id | string | Unique ID (LOLA-YYYYMMDD-HHMMSS) |
| character_name | string | Display name |
| role | string | Primary Role |
| target_audience | string | Target Audience |
| gender | string | Gender |
| age_range | string | Age Range |
| ethnicity | string | Ethnicity/Appearance |
| personality | string | Personality Traits |
| speaking_style | string | Speaking Style |
| voice_accent | string | Voice Accent |
| backstory | text | Background Story |
| primary_language | string | Primary Language |
| content_niche | string | Content Niche |
| image_prompt | text | Generated image prompt |
| negative_prompt | text | Negative prompt |
| image_url | url | Hero image URL |
| voice_id | string | ElevenLabs voice ID |
| voice_name | string | Voice name |
| reference_images | json | Array of reference image URLs |
| scripts | json | Array of starter scripts |
| created_at | datetime | Creation timestamp |
| status | string | pending_image ‚Üí generating ‚Üí ready ‚Üí ready_for_content |

### Learner Coaching Profile (Supabase ‚Äî MVP)

| Column | Type | Description |
|--------|------|-------------|
| learner_id | uuid | Primary key |
| onboarding_answers | jsonb | Raw 5-question responses |
| coaching_dimensions | jsonb | Mapped dimensions (error_response, learning_pref, motivation, pacing, instruction_depth) |
| personality_overrides | jsonb | Optional: self-reported MBTI, Enneagram, etc. |
| session_history | jsonb[] | Array of session summaries with captured errors and coaching adaptations |
| error_patterns | jsonb | Aggregated error patterns across sessions |
| created_at | timestamptz | Profile creation |
| updated_at | timestamptz | Last session |

---

## ¬ß7 ‚Äî Roadmap & Milestones

### Immediate (Feb 2026 ‚Äî Hackathon)

| Task | Status | Notes |
|------|--------|-------|
| Fork Immergo, get running locally | DONE | Forked, adapted to API key mode |
| Gemini Live API with native audio | DONE | `gemini-2.5-flash-native-audio-preview-12-2025` via `google-genai` SDK |
| Profile generation logic (answers ‚Üí coaching dimensions) | DONE | `server/profile_engine.py` ‚Äî 4 demo profiles + dynamic generator |
| Dynamic system prompt (12 principles + profile injection) | DONE | `server/instruction_engine.py` ‚Äî weighted principles, L1 patterns, both-direction |
| L1 interference patterns (JA, KO, EN) | DONE | 3 pattern files in `server/l1_patterns/` |
| Voice chat session via Gemini Live | DONE | WebSocket proxy, PCM streaming, barge-in works |
| 3D avatar with TalkingHead | DONE | Ready Player Me avatar, idle animations, gestures |
| Avatar lip sync (AnalyserNode) | DONE | Real-time volume ‚Üí viseme blend shapes. Mouth moves but sync quality needs polish. |
| Demo profile picker (4 cards) | DONE | Card-based UI with language direction labels |
| Camera/vision input to Gemini | DONE | VideoStreamer sends JPEG frames at 1fps via WebSocket; PiP camera preview in session view |
| 5-question onboarding UI (L1 selection + questions) | NOT STARTED | Currently using pre-built demo profile picker |
| Split-screen demo view (dual sessions) | NOT STARTED | Single session only |
| Educator dashboard mock | NOT STARTED | |
| Cloud Run deployment | NOT STARTED | Dockerfile exists from Immergo |
| Demo video recording | NOT STARTED | |

### Q1 2026 (Post-Hackathon)

- [ ] Video generator workflow (S1-W02)
- [ ] Content publisher workflow (S1-W03)
- [ ] First AI influencer live on social media
- [ ] Learning data persistence (Supabase)
- [ ] Big Five mapping (v1 personality integration)

### Q2 2026

- [ ] SaaS platform MVP: registration, subscription, chat
- [ ] Voice chat integration (production quality)
- [ ] Multi-avatar support
- [ ] Educator creator onboarding flow

### Q3 2026

- [ ] Full chat system with session history
- [ ] Learning data sync with Loka platform (bidirectional)
- [ ] Marketplace beta
- [ ] MBTI + DISC + Enneagram integration (v2)

### Q4 2026

- [ ] Marketplace public launch
- [ ] Unified analytics (educator sees LoLA + Loka data)
- [ ] Full personality framework integration (v3)

---

## ¬ß8 ‚Äî Development & Deployment

### Build Environment

| Tool | Purpose |
|------|---------|
| **Claude Code** | Primary development agent |
| **Claude.ai (this project)** | Architecture, specs, strategic planning |
| **Trev (OpenClaw)** | Autonomous task delegation for parallel work |
| **GitHub** | Source control |
| **Vercel** | Next.js deployment |
| **n8n.orbweva.cloud** | Workflow hosting |

### Commit Practices

Follow ORBWEVA standard: conventional commits, descriptive messages, no force-pushing to main.

### Hackathon Build Strategy

Build the adaptive coaching demo first ‚Äî it's the differentiator. The content pipeline (S1-W01/W01b) already works. The demo must show personality-adaptive coaching producing visibly different outcomes from the same scenario.

---

## ¬ß9 ‚Äî Integration Boundaries

### Loka ‚Üî LoLA Integration

When both Loka and LoLA are in use, shared learning data flows between classroom sessions, AI coaching conversations, and self-study exercises ‚Äî creating the co-active learning triangle.

**Entry Points:** Learners can enter from either door:

- **Through LoLA** ‚Äî wants conversation practice ‚Üí gets personality-adaptive AI coaching ‚Üí captured data builds personal curriculum ‚Üí over time, structured lessons from their own patterns ‚Üí that's Loka
- **Through Loka** ‚Äî wants structured curriculum and classroom tools ‚Üí captured data in exercises and assessments ‚Üí wants more speaking practice ‚Üí that's LoLA
- **Through an educator** ‚Äî teacher uses Loka in classroom, assigns LoLA practice between classes ‚Üí both feed the same data loop ‚Üí educator sees unified progress

### Integration Timeline

| Integration | Description | Target |
|---|---|---|
| Shared learner identity | LoLA users linked to Living Textbook student profiles | Q3 2026 |
| Bidirectional data sync | LoLA conversations generate data that flows to educator Canvas; Canvas data informs LoLA coaching | Q3 2026 |
| Progress sync | LoLA conversation data feeds Living Textbook progress tracking | Q4 2026 |
| Avatar knowledge base | Living Textbook curriculum available to LoLA avatars via ARC format | Q4 2026 |
| Unified analytics | Educator sees student's LoLA practice alongside live session data | 2027+ |

### LoLA Market Domains (Beyond Language)

LoLA is not limited to language learning. The coaching framework and data loop work for any domain where knowledge transfers through co-active conversation:

| Domain | Avatar Role | What Gets Coached |
|---|---|---|
| **Language learning** | Conversation partner | English conversation, grammar, vocabulary |
| **Sales training** | Prospect simulator | Objection handling, closing, discovery |
| **Job interview prep** | Interviewer simulator | Storytelling, answering under pressure |
| **Public speaking** | Audience simulator | Delivery, persuasion, structure |
| **Executive coaching** | Leadership mirror | Difficult conversations, feedback, delegation |
| **Negotiation** | Counterpart simulator | Anchoring positions, concessions, rapport |
| **Customer service** | Customer simulator | Empathy, de-escalation, script adherence |

English for Japanese learners is the first vertical. The architecture supports all of these with the same coaching framework.

---

## ¬ß10 ‚Äî Market Context

### Japan's English Learning Crisis ‚Äî The $8.76 Billion Failure

Japan ranks 96th of 123 countries in the EF English Proficiency Index (2025), declining for 11 consecutive years. Younger cohorts (18-25) now score worse than older generations. Over 50% of students scored zero on speaking sections of standardized tests. The market spends ¬•1.3 trillion ($8.76B) annually with worsening results.

**The problem is psychological, not linguistic.** Cultural face-saving norms (Èù¢Â≠ê/„É°„É≥„ÉÑ) create paralyzing speaking anxiety. 60% of Japanese learners have tried AI conversation apps seeking less stressful alternatives ‚Äî but existing apps offer AI ‚Üî Learner conversation without coaching methodology or educator involvement, reproducing anxiety patterns in digital form.

**This is why the co-active architecture matters:** Every competitor addresses the symptom (lack of practice) with one relationship (AI ‚Üî Learner). Loka + LoLA addresses the cause (psychological barriers that vary by individual) with three relationships connected by shared learning data. The educator provides human trust. The AI provides personality-adaptive coaching. The data loop ensures both sides inform each other.

### Competitive Landscape

$260M+ in VC funding has produced AI language tools that are technically impressive but structurally identical ‚Äî consumer apps with a single line: AI ‚Üî Learner.

| | Speak | Praktika | ELSA | Duolingo | LoLA |
|---|---|---|---|---|---|
| **Funding** | $162M / $1B val | $38M Series A | $60M | Public ($8B+) | Bootstrapped |
| **Users** | 10M+ | 14M+ | 90M+ | 800M+ | Pre-launch |
| **Structured methodology** | ‚úó | ‚úó | ‚úó | ‚úó | 12-principle framework |
| **Personality-adaptive** | ‚úó | ‚úó | ‚úó | ‚úó | MBTI/Big Five/DISC/Enneagram integration |
| **Co-active triangle** | ‚úó | ‚úó | ‚úó | ‚úó | Educator ‚Üî AI ‚Üî Learner |
| **Educator creator platform** | ‚úó | ‚úó | ‚úó | ‚úó | Educators own & monetize avatars |
| **Self-marketing pipeline** | ‚úó | ‚úó | ‚úó | ‚úó | Avatars generate own audiences |
| **Japan depth** | Some JP content | JP launched May 2025 | Pronunciation focus | Gamified, generic | 23 years classroom experience |

### The Praktika Comparison

Praktika ($38M, 3D lip-syncing avatars, 14M downloads, Japanese launched May 2025) is the closest conceptual match but structurally different:

| | Praktika | LoLA |
|---|---|---|
| **Architecture** | AI ‚Üî Learner (line) | Educator ‚Üî AI ‚Üî Learner (co-active triangle) |
| **Model** | Consumer app ‚Äî Praktika owns all avatars | Creator platform ‚Äî educators own their avatars |
| **Methodology** | Claims "psychological support" ‚Äî cites no framework | 12-principle framework integrating personality science |
| **Personalization** | Difficulty level (beginner/intermediate/advanced) | Psychological profile (personality type, learning style, motivation) |
| **Educator role** | None | Central ‚Äî data flows between AI coaching and classroom |
| **User acquisition** | VC-funded app store marketing | Avatars generate own social media content and audiences |

**Praktika is Netflix** ‚Äî it creates content, users consume it. **LoLA is YouTube** ‚Äî educators create their own coaching avatars, build their own audiences, earn their own revenue. LoLA provides the coaching engine and the platform.

### Market Validation: Shizuku AI

a16z invested $15M seed ($75M post-money valuation) in Shizuku AI ‚Äî an AI-native virtual character startup targeting the companion space. This validates the thesis that AI characters can build meaningful, monetizable relationships with users. LoLA rides the same wave into education ‚Äî a larger, more defensible market with clearer monetization and lower regulatory risk.

### The Competitive Moat ‚Äî Three Platform Layers + Four Founder Advantages

**Platform Layers (product moat):**

| Layer | What It Is | Why Competitors Can't Copy |
|-------|-----------|---------------------------|
| **Adaptive Coaching Engine** | 12-principle framework integrating personality science to adapt coaching to each learner's psychological profile | Requires pedagogical + psychological expertise ‚Äî not an engineering problem |
| **Co-Active Learning Triangle** | Shared data connects educator ‚Üî learner ‚Üî AI; classroom data feeds AI, AI data feeds educator | Competitors are AI-only; adding educators would require rebuilding their architecture |
| **Educator Creator Platform + Self-Marketing Pipeline** | Educators build, own, and monetize coaching avatars that generate their own audiences | Competitors own their avatars and spend VC on acquisition |

**Founder Advantages (execution moat):**

| Advantage | Detail |
|-----------|--------|
| **23 Years Teaching** | Hands-on classroom experience with Japanese English learners since 2002 ‚Äî the coaching framework comes from real pedagogy |
| **Operating School** | Accent Language School dogfoods everything ‚Äî features work in real classrooms before they ship |
| **AI + Automation** | Modular n8n-based architecture ‚Äî adaptable and extensible where competitors build closed monoliths |
| **Japan Domain** | Cultural fluency, Japanese business relationships, bilingual operations ‚Äî 23 years of market knowledge |

---

## ¬ß11 ‚Äî Hackathon MVP Demo Specification

### Principle

One fully functional adaptive coaching interaction beats five half-baked features. The demo must show personality-adaptive coaching producing visibly different outcomes ‚Äî and flash the creator platform to show this isn't just an app.

### Demo Flow (3 minutes)

**[0:00‚Äì0:30] ‚Äî The Problem**
"Japan spends $8.76 billion on English learning and ranks 96th ‚Äî declining 11 consecutive years. Every AI app gives you conversation. None of them coach. And none of them include the educator."

**[0:30‚Äì1:00] ‚Äî Learner Onboarding**
5-question intake. Two profiles created side by side:
- Profile A: Analytical, reflective, structure-first, metrics-driven
- Profile B: Social, action-paced, emotion-driven, flow-first

**[1:00‚Äì2:15] ‚Äî Split-Screen Coaching (THE WOW MOMENT)**
Same scenario: Japanese learner produces "I go to the restaurant yesterday"

*Profile A coaching (left screen):*
"Interesting ‚Äî you used the right vocabulary and word order. Let me show you something about how English handles time differently from Japanese. In Japanese, Êò®Êó• carries the tense. In English, the verb itself changes. 'Go' becomes 'went.' You already know the pattern ‚Äî we saw it last session with 'eat/ate.' Same principle. When you're ready, try again."

*Profile B coaching (right screen):*
"You're so close! And honestly, everyone understood exactly what you meant ‚Äî that's real communication! Let's just polish one thing. Picture this: you're telling your friend about last night's amazing ramen. 'I went to the restaurant' ‚Äî past tense 'went.' Try it! ... Perfect! That sounded completely natural."

Both correct pedagogy. Both address the same error. Adapted to different psychological profiles. No competitor does this.

**[2:15‚Äì2:45] ‚Äî Educator Creator View + Data Dashboard (30 seconds)**
Quick flash: educator defining avatar ‚Üí 12-principle framework auto-applied ‚Üí learning data showing progress across both Loka exercises and LoLA sessions ‚Üí unified picture
"This isn't just an app. It's a platform educators build on ‚Äî and the data flows between AI coaching and the classroom."

**[2:45‚Äì3:00] ‚Äî Close**
"No two brains are alike. We finally have the technology to teach that way. Today it's language learning. The architecture works for any domain where humans learn through co-active conversations."

### What NOT to Demo

- Avatar visual quality (loses to Praktika's $38M 3D lip-sync)
- Voice quality comparisons (commodity)
- "Available 24/7" messaging (every app says this)
- Generic AI conversation (ChatGPT does this for free)
- Multiple domains beyond English (plant the seed verbally, don't demo it)

---

---

## ¬ß12 ‚Äî Actual Project Structure (as of v1.2)

```
lola/
‚îú‚îÄ‚îÄ README.md                           # Immergo README (needs update for LoLA)
‚îú‚îÄ‚îÄ GEMINI.md                           # AI coding agent guide (from Immergo)
‚îú‚îÄ‚îÄ CONTRIBUTING.md                     # Contribution guidelines
‚îú‚îÄ‚îÄ Dockerfile                          # Cloud Run container definition
‚îú‚îÄ‚îÄ package.json                        # Vite + frontend dependencies
‚îú‚îÄ‚îÄ vite.config.js                      # Vite build config
‚îú‚îÄ‚îÄ index.html                          # SPA entry point
‚îú‚îÄ‚îÄ app.json                            # App metadata
‚îú‚îÄ‚îÄ docs/
‚îÇ   ‚îú‚îÄ‚îÄ LOLA_HACKATHON_SPEC.md          # Build specification v2.2
‚îÇ   ‚îî‚îÄ‚îÄ LOLA_MASTER_v1.1.md            # This document (canonical master)
‚îú‚îÄ‚îÄ scripts/
‚îÇ   ‚îú‚îÄ‚îÄ dev.sh                          # Local development startup
‚îÇ   ‚îú‚îÄ‚îÄ example.deploy.sh               # Cloud Run deploy template
‚îÇ   ‚îî‚îÄ‚îÄ install.sh                      # Dependency installation
‚îú‚îÄ‚îÄ server/                             # Python backend (FastAPI)
‚îÇ   ‚îú‚îÄ‚îÄ main.py                         # FastAPI app ‚Äî routes, WebSocket, auth
‚îÇ   ‚îú‚îÄ‚îÄ gemini_live.py                  # Gemini Live API session manager
‚îÇ   ‚îú‚îÄ‚îÄ config_utils.py                 # API key / Vertex AI mode detection
‚îÇ   ‚îú‚îÄ‚îÄ profile_engine.py              # 5-question ‚Üí coaching profile + 4 demo profiles
‚îÇ   ‚îú‚îÄ‚îÄ instruction_engine.py          # Profile + L1 ‚Üí system instruction generator
‚îÇ   ‚îú‚îÄ‚îÄ principles.py                  # 12 principles as weighted structured data
‚îÇ   ‚îú‚îÄ‚îÄ l1_patterns/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ __init__.py                # L1 registry (JA, KO, EN)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ japanese.py                # JA interference patterns + bridges (‚ÜíEN)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ korean.py                  # KO interference patterns + bridges (‚ÜíEN)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ english.py                 # EN interference patterns + bridges (‚ÜíJA)
‚îÇ   ‚îú‚îÄ‚îÄ recaptcha_validator.py         # ReCAPTCHA v3 validation
‚îÇ   ‚îú‚îÄ‚îÄ fingerprint.py                 # Device fingerprinting for rate limiting
‚îÇ   ‚îî‚îÄ‚îÄ simple_tracker.py             # Analytics event tracking
‚îú‚îÄ‚îÄ src/                               # Frontend (Vanilla JS + Vite)
‚îÇ   ‚îú‚îÄ‚îÄ main.js                        # App entry point
‚îÇ   ‚îú‚îÄ‚îÄ style.css                      # Global styles
‚îÇ   ‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ app-root.js               # Root component / router
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ view-lola.js              # Main LoLA session ‚Äî avatar, voice, profile picker
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ view-chat.js              # Text chat view (from Immergo)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ view-splash.js            # Landing/splash screen
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ view-missions.js          # Missions view (from Immergo)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ view-summary.js           # Session summary view
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ audio-visualizer.js       # Audio visualization component
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ live-transcript.js        # Live transcription display
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ text-cycler.js            # Text animation component
‚îÇ   ‚îú‚îÄ‚îÄ lib/gemini-live/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ geminilive.js             # Frontend Gemini Live API client (WebSocket)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ mediaUtils.js             # AudioPlayer, AudioRecorder, camera utils
‚îÇ   ‚îî‚îÄ‚îÄ data/
‚îÇ       ‚îî‚îÄ‚îÄ missions.json              # Mission scenarios (from Immergo)
‚îî‚îÄ‚îÄ public/
    ‚îú‚îÄ‚îÄ audio-processors/
    ‚îÇ   ‚îú‚îÄ‚îÄ capture.worklet.js         # Mic capture AudioWorklet
    ‚îÇ   ‚îî‚îÄ‚îÄ playback.worklet.js        # Audio playback AudioWorklet
    ‚îî‚îÄ‚îÄ talkinghead/
        ‚îî‚îÄ‚îÄ playback-worklet.js        # TalkingHead audio worklet
```

## ¬ß13 ‚Äî Implementation Notes & Known Issues

### Gemini Live API Configuration (ACTUAL)

```javascript
// Frontend setup (geminilive.js)
{
  responseModalities: ["AUDIO"],
  temperature: 0.7,          // Lowered from 1.0 for consistent instruction-following
  voiceName: "Kore",         // Female voice (changed from Puck/male)
  enableAffectiveDialog: false,  // NOT supported on native audio models
  proactivity: null,             // NOT supported on native audio models
  inputAudioTranscription: true,
  outputAudioTranscription: true,
  automaticActivityDetection: {
    disabled: false,
    silence_duration_ms: 2000,
    prefix_padding_ms: 500,
  }
}
```

### Known Issues (as of v1.2)

| Issue | Severity | Notes |
|-------|----------|-------|
| Lip sync is volume-based, not phoneme-based | Medium | AnalyserNode maps overall volume to mouth openness. Not true viseme detection. Acceptable for demo but not production quality. |
| Avatar model is generic RPM | Low | Single default avatar. Spec calls for 2 distinct coaches (analyst vs explorer). |
| `enable_affective_dialog` not available on native audio | High (spec gap) | Original spec relies on affective dialog for emotion detection. Native audio models don't support it. Need alternative approach or model change. |
| `sendClientContent()` mid-session updates not tested | Medium | Core differentiator from spec ‚Äî needs validation with native audio model. |
| Vision (camera) not fully wired in frontend | Medium | Backend supports video input queue; frontend camera capture UI not connected to LoLA view. |
| 5-question onboarding not built | Low (demo) | Using 4 pre-built demo profiles. Full onboarding is Phase 2. |
| No session persistence | Low | Each session starts fresh. No cross-session memory. |

### Voice Configuration

| Voice | Gender | Used For | Notes |
|-------|--------|----------|-------|
| Kore | Female | All profiles (current) | Warm, clear. Set in `view-lola.js` |
| Puck | Male | Not used (was default) | Changed to Kore for better coaching persona |

Spec calls for distinct voices per coach avatar (Profile A calm/measured, Profile B warm/energetic). Not yet implemented ‚Äî currently all profiles use Kore.

---

*This document is updated as LoLA progresses through development. When this document conflicts with older docs (LOLA_PRD_v1, LOLA_PRD_v2, lola_shizuku_strategic_scope), this document wins.*
